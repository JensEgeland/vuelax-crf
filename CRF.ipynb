{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package we are using requires the data to be presented in a very specific format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "features_labels = pd.read_csv(\"data/features-labels.csv\")\n",
    "features_labels = features_labels[~features_labels['label'].isna()]\n",
    "features_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_0 = features_labels[features_labels['offer_id'] == 0]\n",
    "print(offer_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for python-crfsuite\n",
    "\n",
    "The inputs to the algorithm must follow a particular format, where each token has its features represented by key-value pairs, each token may also have different features based on different factors, like its position. The following function takes in a dataframe and returns the corresponding features that can be consumed by the training method of our algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def is_punctuation(token):\n",
    "    return token in punctuation\n",
    "\n",
    "def is_numeric(token):\n",
    "    try:\n",
    "        float(token.replace(\",\", \"\"))\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurise(sentence_frame, current_idx):\n",
    "    current_token = sentence_frame.iloc[current_idx]\n",
    "    token = current_token['token']\n",
    "    position = current_token['position']\n",
    "    token_count = current_token['token_count']\n",
    "    pos = current_token['pos_tag']\n",
    "    \n",
    "    # Shared features across tokens\n",
    "    features = {\n",
    "            'bias': True,\n",
    "            'word.lower': token.lower(),\n",
    "            'word.istitle': token.istitle(),\n",
    "            'word.isdigit': is_numeric(token),\n",
    "            'word.ispunct': is_punctuation(token),\n",
    "            'word.position':position,\n",
    "            'word.token_count': token_count,\n",
    "            'postag': pos, \n",
    "    }\n",
    "    \n",
    "    if current_idx > 0: # The word is not the first one...\n",
    "        prev_token = sentence_frame.iloc[current_idx-1]['token']\n",
    "        prev_pos = sentence_frame.iloc[current_idx-1]['pos_tag']\n",
    "        features.update({\n",
    "            '-1:word.lower': prev_token.lower(),\n",
    "            '-1:word.istitle':prev_token.istitle(),\n",
    "            '-1:word.isdigit': is_numeric(prev_token),\n",
    "            '-1:word.ispunct': is_punctuation(prev_token),\n",
    "            '-1:postag':prev_pos \n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    \n",
    "    if current_idx < len(sentence_frame) - 1: # The word is not the last one...\n",
    "        next_token = sentence_frame.iloc[current_idx+1]['token']\n",
    "        next_tag = sentence_frame.iloc[current_idx+1]['pos_tag']\n",
    "        features.update({\n",
    "            '+1:word.lower': next_token.lower(),\n",
    "            '+1:word.istitle': next_token.istitle(),\n",
    "            '+1:word.isdigit': is_numeric(next_token),\n",
    "            '+1:word.ispunct': is_punctuation(next_token),\n",
    "            '+1:postag': next_tag \n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "featurise(offer_0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `featurize` only works over a single token, we need another method to return all the values for a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_sentence(sentence_frame):\n",
    "    labels = list(sentence_frame['label'].values)\n",
    "    features = [featurize(sentence_frame, i) for i in range(len(sentence_frame))]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "features, labels = featurize_sentence(offer_0)\n",
    "print(features[1])\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the dataset is split into tokens, however, since we are working on sequence labelling we need to provide the algorithm with sequences. The following method takes care of rolling up the tokens into two lists of sentences and their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollup(dataset):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    offers = dataset.groupby('offer_id')\n",
    "    for name, group in offers:\n",
    "        sqs, lbls = featurize_sentence(group)\n",
    "        sequences.append(sqs)\n",
    "        labels.append(lbls)\n",
    "\n",
    "    return sequences, labels\n",
    "\n",
    "all_sequences, all_labels = rollup(features_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much like in any other supervised problem, we need to split our training dataset into two (preferably three) sets of data, we can use `train_test_split` for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_docs, test_docs, train_labels, test_labels = train_test_split(all_sequences, all_labels)\n",
    "\n",
    "len(train_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CRF  \n",
    "\n",
    "Though one can use a *sklearn-like* interface to create, train and infer with python-crfsuite, I've decided to just use the original package and do all \"by hand\". \n",
    "\n",
    "The first step is to create an object of the class `Trainer`, then append our training sequences to it. Finally we can set some parameters for the training phase, feel free to play with these, as they may improve the quality of the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(train_docs, train_labels):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 200, \n",
    "\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call the method train, that will, at the same time, save the model to a file that we can then use to perform inferences in new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('model/vuelax.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling \"unseen\" sequences\n",
    "\n",
    "To perform sequence labelling on instances that our algorithm did not see during training it is necessary to use an object of the `Tagger` class, and then load our saved model into it by using the `open` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_tagger = pycrfsuite.Tagger()\n",
    "crf_tagger.open('model/vuelax.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each one of the sentences needs to be processed and put in the format required for the tagger to work, that means, have the same features we used for training. We already have this in our `test_docs`, and we can use them direclty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = crf_tagger.tag(test_docs[2])\n",
    "print(\"Predicted: \",predicted_tags)\n",
    "print(\"Correct  : \",test_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the tagger\n",
    "\n",
    "While there may be better ways to evaluate the performance of the tagger, we'll use the traditional tools of a classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "for i in range(len(test_docs)):\n",
    "    all_true.extend(test_labels[i])\n",
    "    all_pred.extend(crf_tagger.tag(test_docs[i]))\n",
    "    \n",
    "len(all_true), len(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_true, all_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general terms, our tagger seems to be performing good. It seems to be struggling to find all the `f` tokens, but the rest. The ones we care the most about are being correctly labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
